### RUN COMMAND :
1.  just tweet only
    scrapy crawl TweetScraper -a query="covid19,India"
2.  tweet and users
    scrapy crawl TweetScraper -a query="covid19" -a crawl_user=True

### Sink Process:

1. Write Crawled results into a FILE
    The tweets will be saved to disk in `./Data/tweet/` in default settings and `./Data/user/` is for user data.
    The file format is JSON. Change the `SAVE_TWEET_PATH` and `SAVE_USER_PATH` in `TweetScraper/settings.py` if you want another location.
2. INSERT Crawled Results into MYSQL
    In you want to save the data to MYSQL
    change the `ITEM_PIPELINES` in `TweetScraper/settings.py`
    from `TweetScraper.pipelines.SaveToFilePipeline` to `TweetScraper.pipelines.SaveToMYSQLPipeline`.

### Query Details

1. In the run command query -  `query` is a list of keywords seperated by comma and quoted by `"`.
The query can be any thing (keyword, hashtag, etc.) you want to search in [Twitter Search](https://twitter.com/search-home).
`TweetScraper` will crawl the search results of the query and save the tweet content and user information.
You can also use the following operators in each query (from [Twitter Search](https://twitter.com/search-home)):
	
	| Operator | Finds tweets... |
	| --- | --- |
	| twitter search | containing both "twitter" and "search". This is the default operator. |
	| **"** happy hour **"** | containing the exact phrase "happy hour". |
	| love **OR** hate | containing either "love" or "hate" (or both). |
	| beer **-** root | containing "beer" but not "root". |
	| **#** haiku | containing the hashtag "haiku". |
	| **from:** alexiskold | sent from person "alexiskold". |
	| **to:** techcrunch | sent to person "techcrunch". |
	| **@** mashable | referencing person "mashable". |
	| "happy hour" **near:** "san francisco" | containing the exact phrase "happy hour" and sent near "san francisco". |
	| **near:** NYC **within:** 15mi | sent within 15 miles of "NYC". |
	| superhero **since:** 2010-12-27 | containing "superhero" and sent since date "2010-12-27" (year-month-day). |
	| ftw **until:** 2010-12-27 | containing "ftw" and sent up to date "2010-12-27". |
	| movie -scary **:)** | containing "movie", but not "scary", and with a positive attitude. |
	| flight **:(** | containing "flight" and with a negative attitude. |
	| traffic **?** | containing "traffic" and asking a question. |
	| hilarious **filter:links** | containing "hilarious" and linking to URLs. |
	| news **source:twitterfeed** | containing "news" and entered via TwitterFeed |


### Other parameters
* `lang[DEFAULT='']` allow to choose the language of tweet scrapped.
This is not part of the query parameters, it is a different part in the search API URL
* `top_tweet[DEFAULT=False]`, if you want to query only top_tweets or all of them
* `crawl_user[DEFAULT=False]`, if you want to crawl users, author's of tweets in the same time

